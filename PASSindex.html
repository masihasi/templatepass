<!doctype html>
<html>

<head>
  <title>Project Title</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
        
          
          </div>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
      
      
      
      <div class="content">
      <div class="content-table flex-column">    

	    
	                  
  <!-- Page Content-->
<div class="container-fluid p-0">
    <!-- About-->
    <section class="resume-section" id="about">
        <div class="resume-section-content">
            <h1 class="mb-0">
                PASS
                <span class="text-info">Project (  Persian Audio Source Separation ) </span>
            </h1>
        
          
            
  
  
          
        </div>
      
	      
	    
	      
         
              
       <!-------------------------------------------------------------------------------------------------------------------------------->

  	
	
           
         
     <!-------------------------------------------------------------------------------------------->

	 <!--Start Intro-->
	  <div class="flex-row">
          <div class="flex-item flex-item-stretch flex-column">
	    <img class="image max-width-300  max-height-300 " src="imgpass/pass.jpeg">
          </div>
          <div class="flex-item flex-column">
            <p class="text">
              <a target="_blank" ></a>Internship of Asr Gooyesh Pardaz <br>
              <a target="_blank" ></a> Phone Number:</a> (+98 21) 61931000<br>
              <a target="_blank" ></a> Email: </a>nfo@asr-gooyesh.com<br>
              <a target="_blank" ></a>  Address: Unit 10, No. 2, Boroumand Alley, Teymoori Blv.,<br>
              <a target="_blank" href="javascript:void(0)"></a> Habibollah Blv., Azadi Ave, Tehran-Irany<br>
            </p>
          </div>
	     </div>     
	      
	      
 
	      
	      
	<!--End Text Only-->
        <!-------------------------------------------------------------------------------------------->
        <!--Start Text with Buttons-->
        <div class="flex-row">
          <div class="flex-item flex-column">
        	  
            <div class="control-group">
	      <a class="custom-button-flat" href="http://asr-gooyesh.com/en/" target="_blank"><img src="img/home.png"></a>
              <a class="custom-button-flat" href="https://telegram.me/asrgooyeshpardaz" target="_blank"><img src="img/telegram.png"></a>
              <a class="custom-button-flat" href="https://www.linkedin.com/company/asr-gooyesh-pardaz-co-/?originalSubdomain=ir" target="_blank"><img src="img/linkedin.png"></a>
	      <a class="custom-button-flat" href="https://www.instagram.com/asrgooyesh/" target="_blank"><img src="img/instagram.png"></a>
              <a class="custom-button-flat" href="https://github.com/agp-internship" target="_blank"><img src="img/github.png"></a>

                
            </div>
 
          </div>
        </div>
      
      
      
              
        <!-- Page Content-->
<div class="container-fluid p-0">
    <!-- About-->
    <section class="resume-section" id="about">
        <div class="resume-section-content">
       

		
            
            <div class="lead mb-5">

The Persian audio source separation project aims to separate two or more audio files from one audio containing two or more audio sources. Consider a audio file of a meeting in which four people are talking at the same time, and background music is playing; the final product of this project should be able to output five separate audio files, each containing one sound from one of them. Among these audio sources (4 people and a music source). The library in the references section is an open-source project ready for this work. This project may be enough for us (it may not depend on the language). Necessary measures should be taken to personalize it for the Persian language. After preliminary research and making a demo in the Persian language, it is time to test the product. It is placed as a research product in the field of sound processing. It is expected that an initial report will be posted on the company's blog after the research, and the community of this report and weekly reports will also make the project's final report.
                
                        </div>
  
        </div>
      
      
</div>
                  <hr>

      
      
      
        
        
        
        
        
        
        
	     

    <!-- Soroush Gooran -->
    <section class="resume-section" id="Mentor">
        <div class="resume-section-content">
            <h2 class="mb-5">Dr. Soroush Gooran</h2>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <img class="subheading mb-2" src="imgpass/DrGooran.png" style="width: 20%; padding: 5px" alt="AUT">

                    <h3 class="mb-0"> <a  style="color: black; font-size: x-large;font-weight: 500"
                                         href="">
                    </a></h3>
                    <p class="mb-2">  </p>
                    <p>     About Mentor:     PhD student in Artificial Intelligence at Sharif University of Technology  </p>

                </div>
            </div>      
        </div>
	    
	    
	    
	                      <hr>

	    
	    
	    
	       
	    
	    
     
    <!-- Masoumeh siar-->
    <section class="resume-section" id="Masoumehsiar">
        <div class="resume-section-content">
            <h2 class="mb-5">Masoumeh siar</h2>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <img class="subheading mb-2" src="imgpass/masoumeh.png" style="width: 20%; padding: 5px" alt="AUT">

                    <h3 class="mb-0"> <a  style="color: black; font-size: x-large;font-weight: 500"
                                         href="https://arxiv.org/pdf/1712.04555.pdf">Classification vs. Regression in Supervised Learning for Single Channel Speaker Count Estimation
                    </a></h3>
		   <p class="mb-2">  </p>

                    <div> In2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2018 Apr 15 (pp. 436-440). IEEE.</div>
                    <p class="mb-2">  </p>
                    <p> Abstract: The task of estimating the maximum number of concurrent speakers from single channel mixtures is important for various audio-based applications, such as blind source separation, speaker diarisation, audio surveillance or auditory scene classification. Building upon powerful machine learning methodology, we develop a Deep Neural Network (DNN) that estimates a speaker count. While DNNs efficiently map input representations to output targets, it remains unclear how to best handle the network output to infer integer source count estimates, as a discrete count estimate can either be tackled as a regression or a classification problem. In this paper, we investigate this important design decision and also address complementary parameter choices such as the input representation. We evaluate a stateof-the-art DNN audio model based on a Bi-directional Long Short-Term Memory network architecture for speaker count estimations. Through experimental evaluations aimed at identifying the best overall strategy for the task and show results for five seconds speech segments in mixtures of up to ten speakers.</p>
                    
                </div>
            </div>

       
		
		
	 <!--Start Text with Buttons-->
        <div class="flex-row">
          <div class="flex-item flex-column">
        	  
            <div class="control-group">
	         <a class="custom-button-flat" href="https://github.com/aishoot/Concurrent_Speakers_Counter" target="_blank"><img src="img/github.png"></a>
                 <a class="custom-button-flat" href=" " target="_blank"><img src="img/telegram.png"></a>

                
            </div>
 
          </div>
        </div>   
		
		
            
        </div>
 	    
	    
       <hr>
	    
 
	     
	    
	    
	    
	    
	    
	
        
        
    <!-- Fatemeh Jafari-->
    <section class="resume-section" id="FatemehJafari">
        <div class="resume-section-content">
            <h2 class="mb-5">Fatemeh Jafari</h2>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <img class="subheading mb-2" src="imgpass/jafari.jpg" style="width: 20%; padding: 5px" alt="AUT">

                    <h3 class="mb-0"> <a  style="color: black; font-size: x-large;font-weight: 500"
                                         href="https://arxiv.org/pdf/1805.02410.pdf">MMDENSELSTM: AN EFFICIENT COMBINATION OF CONVOLUTIONAL AND
RECURRENT NEURAL NETWORKS FOR AUDIO SOURCE SEPARATION
                    <p class="mb-2">  </p>
                    </a></h3>
                    <div>  In2018 16th International workshop on acoustic signal enhancement (IWAENC) 2018 Sep 17 (pp. 106-110). IEEE.</div>
                    <p class="mb-2">  </p>
                    <p> Abstract: Deep neural networks have become an indispensable technique for audio source separation (ASS). It was recently reported that a variant of CNN architecture called MMDenseNet was successfully employed to solve the ASS problem of estimating source amplitudes, and state-of-the-art results were obtained for DSD100 dataset. To further enhance
MMDenseNet, here we propose a novel architecture that integrates long short-term memory (LSTM) in multiple scales with skip connections to efficiently model long-term structures within an audio context. The experimental results show
that the proposed method outperforms MMDenseNet, LSTM and a blend of the two networks. The number of parameters and processing time of the proposed model are significantly
less than those for simple blending. Furthermore, the proposed method yields better results than those obtained using ideal binary masks for a singing voice separation task.</p>
                    
                </div>
            </div>

         <div class="social-icons">
 
		  <a class="custom-button-flat" href="https://github.com/tsurumeso/vocal-remover" target="_blank"><img src="img/github.png"></a>
                 <a class="custom-button-flat" href=" " target="_blank"><img src="img/telegram.png"></a>
              </div>   
            
        </div>
 	    
	    
	    
        
        
        
        
        
        
        
        
        
        
        
        
        
  
        </div>
      </div>
    </div>
  </div>
</body>

</html>
